{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqeQ0cHQnCbv",
        "outputId": "50c7750f-fe4b-4947-f8a3-bbfe1211b2ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_decision_forests\n",
            "  Downloading tensorflow_decision_forests-1.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (2.0.3)\n",
            "Collecting tensorflow~=2.16.1 (from tensorflow_decision_forests)\n",
            "  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.16.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.4.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (0.43.0)\n",
            "Collecting wurlitzer (from tensorflow_decision_forests)\n",
            "  Downloading wurlitzer-3.1.0-py3-none-any.whl (8.4 kB)\n",
            "Collecting tf-keras~=2.16 (from tensorflow_decision_forests)\n",
            "  Downloading tf_keras-2.16.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ydf (from tensorflow_decision_forests)\n",
            "  Downloading ydf-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (0.2.0)\n",
            "Collecting h5py>=3.10.0 (from tensorflow~=2.16.1->tensorflow_decision_forests)\n",
            "  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow~=2.16.1->tensorflow_decision_forests)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (4.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (1.63.0)\n",
            "Collecting tensorboard<2.17,>=2.16 (from tensorflow~=2.16.1->tensorflow_decision_forests)\n",
            "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_decision_forests\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install keras\n",
        "!pip install scikit-learn\n",
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DF36u6uEwBMB"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Sequential, Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import Resizing\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow_decision_forests as tfdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rE7GAxmts9cC"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "def pca_features(data: np.ndarray, n_components: int = 10) -> np.ndarray:\n",
        "    flattened_data = np.array([img.flatten() for img in data])\n",
        "    data_processed = PCA(n_components=n_components).fit_transform(flattened_data)\n",
        "    return data_processed\n",
        "\n",
        "\n",
        "def t_sne_features(data: np.ndarray, n_components: int = 10):\n",
        "    data_embeded = TSNE(n_components=n_components,\n",
        "                        learning_rate='auto',\n",
        "                        init='random',\n",
        "                        perplexity=3).fit_transform(data)\n",
        "    print(data_embeded.shape)\n",
        "    return data_embeded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAlpGeePtNK0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2 as cv\n",
        "import pandas as pd\n",
        "\n",
        "def load_images_from_folder(folder: str) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Функция подгрузки необходимого набора искусственных изображений из передаваемого каталога.\n",
        "\n",
        "    :param folder: папка с изображениями, сохраненными в формате .png\n",
        "\n",
        "    :return: список формата Numpy, содержащие AIO в объектах класса Image из Pillow\n",
        "    \"\"\"\n",
        "\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = cv.imread(os.path.join(folder, filename), cv.IMREAD_GRAYSCALE)\n",
        "        if img is not None:\n",
        "            images.append(np.asarray(img).astype(np.float32))\n",
        "    return np.asarray(images)\n",
        "\n",
        "folder_images = \"/content\"\n",
        "images = load_images_from_folder(folder_images)\n",
        "pca_features_ = pca_features(images, n_components=30)\n",
        "df_wheat = pd.read_csv(\"/content/wheat_pheno_num_sync.csv\")\n",
        "labels = df_wheat[[\"Урожайность.зерна..г.\", \"Высота.растений..см\"]].to_numpy()\n",
        "\n",
        "# импутирование данных\n",
        "# (Пока просто средними значениями) импутируем данные, поскольку присутствуют пропуски\n",
        "# imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imp = KNNImputer(n_neighbors=2, weights='uniform')\n",
        "labels = imp.fit_transform(labels.reshape(-1, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "6sy6suYiw6hI",
        "outputId": "cad4595a-57f7-4c16-fe81-af4c6a915f26"
      },
      "outputs": [
        {
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-6-9c9019948c53>, line 47)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-9c9019948c53>\"\u001b[0;36m, line \u001b[0;32m47\u001b[0m\n\u001b[0;31m    metrics = ComboModelTuner.custom_cv(total_hp={\"batch_size_ll\": 64, \"num_epochs_ll\": 30},\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ],
      "source": [
        "# обучение модели со случайным лесом\n",
        "\n",
        "def hyper_tuning(model: 'ComboModel', iters_num: int, hps_cnn: dict, hps_reg: dict):\n",
        "    valid_mae_label_1, valid_mae_label_2 = [], []\n",
        "    valid_mse_label_1, valid_mse_label_2 = [], []\n",
        "    valid_accuracy_label_1, valid_accuracy_label_2 = [], []\n",
        "\n",
        "    for iter_ in range(iters_num):\n",
        "        # Сборка комбинации случайных гиперпараметров в заданын границах\n",
        "        cnn_hp_comb, reg_hp_comb = {}, {}\n",
        "\n",
        "        for param in hps_cnn:\n",
        "            if len(hps_cnn[param]) > 1:\n",
        "                if any(isinstance(x, bool) for x in hps_cnn[param]) or any(isinstance(x, str) for x in hps_cnn[param]):\n",
        "                    cnn_hp_comb[param] = hps_cnn[param][np.random.randint(len(hps_cnn[param]))]\n",
        "                else:\n",
        "                    cnn_hp_comb[param] = np.random.randint(low=min(hps_cnn[param]), high=max(hps_cnn[param]))\n",
        "            else:\n",
        "                cnn_hp_comb[param] = hps_cnn[param][0]\n",
        "\n",
        "        for param in hps_reg:\n",
        "            if len(hps_reg[param]) > 1:\n",
        "                if any(isinstance(x, bool) for x in hps_reg[param]) or any(isinstance(x, str) for x in hps_reg[param]):\n",
        "                    reg_hp_comb[param] = hps_reg[param][np.random.randint(len(hps_reg[param]))]\n",
        "                else:\n",
        "                    reg_hp_comb[param] = np.random.randint(low=min(hps_reg[param]), high=max(hps_reg[param]))\n",
        "            else:\n",
        "                reg_hp_comb[param] = hps_reg[param][0]\n",
        "\n",
        "        print(cnn_hp_comb)\n",
        "\n",
        "        model = SimpleCNNModel(n_epochs=20,\n",
        "                               n_row=200,\n",
        "                               n_col=200,\n",
        "                               input_channels=1,\n",
        "                               random_seed=1234567890,\n",
        "                               n_dict_features=30,\n",
        "                               n_trait=2,\n",
        "                               data_train=train_images_,\n",
        "                               labels_train=train_labels_,\n",
        "                               features_train=train_features_,\n",
        "                               data_test=test_images_,\n",
        "                               features_test=test_features_,\n",
        "                               labels_test=test_labels_)\n",
        "\n",
        "            # model = SimpleCNNModel()\n",
        "          metrics = ComboModelTuner.custom_cv(total_hp={\"batch_size_ll\": 64, \"num_epochs_ll\": 30},\n",
        "                                              cnn_hp=cnn_hp_comb,\n",
        "                                              model=model)\n",
        "\n",
        "        # считаем ошибку модели на тестовой выборке\n",
        "        print(f\"Random Tuning iter #{iter_} finished successfully\")\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ComboModel:\n",
        "\n",
        "    n_epochs: int = 100\n",
        "    n_row: int = 200\n",
        "    n_col: int = 200\n",
        "    input_channels: int = 1\n",
        "    n_data: int = 100  # len(aio_labels)\n",
        "    random_seed: int = 1234567890\n",
        "    n_dict_features: int = 30\n",
        "    n_trait: int = 1\n",
        "    data_train: np.ndarray = np.ndarray([])\n",
        "    label_train: np.ndarray = np.ndarray([])\n",
        "\n",
        "    optimizer: keras.optimizers.Optimizer = None\n",
        "    model: keras.models.Model = None\n",
        "\n",
        "    def combo_model_functional(self, hp):\n",
        "        \"\"\"\n",
        "        Функция построения модели нейросети с функциональным интерфейсом keras\n",
        "\n",
        "        :param hp: набор гиперпараметров, отвечающих за конфигурация нейросети\n",
        "        :return: граф-представление нейросети\n",
        "        \"\"\"\n",
        "\n",
        "        inp_node = Input((self.n_row, self.n_col, self.input_channels), name=\"img_input\")\n",
        "        inp_dict_model = Input(self.n_dict_features, name=\"pop_struct_input\")\n",
        "\n",
        "        conv_node_1 = Conv2D(hp['first_conv2d_out_channels'],\n",
        "                             kernel_size=(hp['first_conv2d_kernel_size'], hp['first_conv2d_kernel_size']),\n",
        "                             padding='same',\n",
        "                             strides=(1, 1),\n",
        "                             activation=hp['first_conv2d_activation'], name=\"conv_map_1\")(inp_node)\n",
        "        if hp['need_extra_conv2d']:\n",
        "            conv_node_1 = Conv2D(hp['extra_conv2d_out_channels'],\n",
        "                                 kernel_size=(hp['extra_conv2d_kernel_size'], hp['extra_conv2d_kernel_size']),\n",
        "                                 padding='same',\n",
        "                                 strides=(1, 1),\n",
        "                                 activation=hp['extra_conv2d_activation'], name=\"conv_map_extra\")(conv_node_1)\n",
        "\n",
        "        if hp['need_batch_norm_after_first_conv2d']:\n",
        "            batch_node_1 = BatchNormalization()(conv_node_1)\n",
        "            mp_node_1 = MaxPooling2D(pool_size=(2, 2))(batch_node_1)\n",
        "        else:\n",
        "            mp_node_1 = MaxPooling2D(pool_size=(2, 2))(conv_node_1)\n",
        "\n",
        "        conv_node_2 = Conv2D(hp['second_conv2d_out_channels'],\n",
        "                             kernel_size=(hp['second_conv2d_kernel_size'], hp['second_conv2d_kernel_size']),\n",
        "                             padding='same',\n",
        "                             strides=(1, 1),\n",
        "                             activation=hp['second_conv2d_activation'], name=\"conv_map_2\")(mp_node_1)\n",
        "\n",
        "        if hp['need_batch_norm_after_second_conv2d']:\n",
        "            batch_node_2 = BatchNormalization()(conv_node_2)\n",
        "            mp_node_2 = MaxPooling2D(pool_size=(2, 2), name=\"max_pool_map\")(batch_node_2)\n",
        "        else:\n",
        "            mp_node_2 = MaxPooling2D(pool_size=(2, 2), name=\"max_pool_map\")(conv_node_2)\n",
        "\n",
        "        if hp['need_deconv_block']:\n",
        "            deconv_node_2 = Conv2DTranspose(\n",
        "                hp['second_conv2d_out_channels'],\n",
        "                kernel_size=(hp['second_conv2d_kernel_size'], hp['second_conv2d_kernel_size']),\n",
        "                padding='same',\n",
        "                strides=(2, 2),\n",
        "                activation=hp['second_conv2d_activation'],\n",
        "                name=\"deconv_2\"\n",
        "            )(mp_node_2)\n",
        "            concat_node_2 = Concatenate(name=\"concat_2\", axis=3)([deconv_node_2, conv_node_2])\n",
        "            conv_node_deconv_2 = Conv2D(\n",
        "                hp['second_conv2d_out_channels'],\n",
        "                kernel_size=(hp['second_conv2d_kernel_size'], hp['second_conv2d_kernel_size']),\n",
        "                padding='same',\n",
        "                strides=(1, 1),\n",
        "                activation=hp['second_conv2d_activation'],\n",
        "                name=\"conv_deconv_2\"\n",
        "            )(concat_node_2)\n",
        "            deconv_node_1 = Conv2DTranspose(\n",
        "                hp['first_conv2d_out_channels'],\n",
        "                kernel_size=(hp['first_conv2d_kernel_size'], hp['first_conv2d_kernel_size']),\n",
        "                padding='same',\n",
        "                strides=(2, 2),\n",
        "                activation=hp['first_conv2d_activation'],\n",
        "                name=\"deconv_1\"\n",
        "            )(conv_node_deconv_2)\n",
        "            concat_node_1 = Concatenate(name=\"concat_1\", axis=3)([deconv_node_1, conv_node_1])\n",
        "            mp_node_2 = Conv2D(\n",
        "                hp['first_conv2d_out_channels'],\n",
        "                kernel_size=(hp['first_conv2d_kernel_size'], hp['first_conv2d_kernel_size']),\n",
        "                padding='same',\n",
        "                strides=(1, 1),\n",
        "                activation=hp['first_conv2d_activation'],\n",
        "                name=\"conv_deconv_1\"\n",
        "            )(concat_node_1)\n",
        "\n",
        "        if hp['use_gap_1_or_flatten_0'] == 0:\n",
        "            flatten_node = Flatten(name='flatten')(mp_node_2)\n",
        "            dense_node = Dense(hp['num_feature_output'], activation=hp['dense_output_activation'],\n",
        "                               name=\"img_feature_output\")(flatten_node)\n",
        "        elif hp['use_gap_1_or_flatten_0'] == 1:\n",
        "            dense_node = GlobalAveragePooling2D(name=\"img_feature_output\")(mp_node_2)\n",
        "\n",
        "        concatenate_features = Concatenate(name=\"concat_features\")(inp_dict_model, dense_node)\n",
        "\n",
        "        reg_forest_1 = tfdf.keras.RandomForestModel(task=tfdf.keras.Task.REGRESSION,\n",
        "                                                    num_trees=hp['num_estimators'],\n",
        "                                                    max_depth=hp['max_depth'],\n",
        "                                                    bootstrap_training_dataset=hp['bootstrap'])\n",
        "        forest_1_pred = reg_forest_1(concatenate_features)\n",
        "\n",
        "        reg_forest_2 = tfdf.keras.RandomForestModel(task=tfdf.keras.Task.REGRESSION,\n",
        "                                                    num_trees=hp['num_estimators'],\n",
        "                                                    max_depth=hp['max_depth'],\n",
        "                                                    bootstrap_training_dataset=hp['bootstrap'])\n",
        "        forest_2_pred = reg_forest_2(concatenate_features)\n",
        "\n",
        "        combo_model = Model(inputs=[inp_node, inp_dict_model], outputs=[forest_1_pred, forest_2_pred],\n",
        "                            name=\"feature_model\")\n",
        "\n",
        "        self.model = combo_model\n",
        "\n",
        "    def build(self, hp):\n",
        "        \"\"\"\n",
        "        Builds a convolutional model.\n",
        "        \"\"\"\n",
        "        # Гиперпараметры сверточной части модели\n",
        "        model_hp = {\n",
        "            # сначала идут параметры сверточной части модели\n",
        "            'first_conv2d_out_channels': [32, 64],\n",
        "            'first_conv2d_kernel_size': [3, 5, 7],\n",
        "            'first_conv2d_activation': ['tanh', 'relu'],\n",
        "            'need_extra_conv2d': [False, True],\n",
        "            'extra_conv2d_out_channels': [32, 64],\n",
        "            'extra_conv2d_kernel_size': [3, 5, 7],\n",
        "            'extra_conv2d_activation': ['tanh', 'relu'],\n",
        "            'need_batch_norm_after_first_conv2d': [True, False],\n",
        "            'second_conv2d_kernel_size': [3, 5],\n",
        "            'second_conv2d_out_channels': [128, 64],\n",
        "            'second_conv2d_activation': ['tanh', 'relu'],\n",
        "            'need_batch_norm_after_second_conv2d': [True, False],\n",
        "            'dense_output_activation': ['sigmoid', 'linear'],\n",
        "            'use_gap_1_or_flatten_0': [1, 0],\n",
        "            'need_deconv_block': [False, True],\n",
        "            'num_feature_output': [128, 64, 256],\n",
        "            # а дальше идут параметры регрессионного случайного леса\n",
        "            'n_estimators': [5, 20, 50, 100],\n",
        "            'max_features': ['auto', 'sqrt'],\n",
        "            'max_depth': [(i + 1) * 5 for i in range(7)],\n",
        "            'min_samples_split': [2, 6, 10],\n",
        "            'bootstrap': [True, False]\n",
        "        }\n",
        "\n",
        "        # возвращаем собранную модель\n",
        "        return self.combo_model_functional(model_hp)\n",
        "\n",
        "    @staticmethod\n",
        "    @tf.function\n",
        "    def custom_loss_mse(y_true: np.ndarray, y_pred: np.ndarray):\n",
        "        error = y_true - y_pred\n",
        "        squared_error = tf.square(error)\n",
        "        result = tf.reduce_mean(squared_error)\n",
        "\n",
        "        return result\n",
        "\n",
        "    @staticmethod\n",
        "    @tf.function\n",
        "    def custom_loss_mae(y_true: np.ndarray, y_pred: np.ndarray):\n",
        "        error = y_true - y_pred\n",
        "        abs_error = tf.abs(error)\n",
        "        result = tf.reduce_mean(abs_error)\n",
        "\n",
        "        return result\n",
        "\n",
        "    # Function to run the train step.\n",
        "    # здесь надо подумать как исправить эту функцию\n",
        "    @tf.function\n",
        "    def run_train_step(self, images_, pop_comps_, labels_1_, labels_2_):\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits_1, logits_2 = self.model(images_, pop_comps_)\n",
        "            loss_1 = loss_fn(labels, logits_1)\n",
        "            loss_2 = loss_fn(labels, logits_2)\n",
        "            # Add any regularization losses.\n",
        "            if self.model.losses:\n",
        "                loss_1 += tf.math.add_n(self.model.losses)\n",
        "                loss_2 += tf.math.add_n(self.model.losses)\n",
        "        gradients = tape.gradient(loss_1, self.model.trainable_variables)\n",
        "        gradients = tape.gradient(loss_2, self.model.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
        "\n",
        "    # Function to run the validation step.\n",
        "    @tf.function\n",
        "    def run_val_step(self, images_, pop_comps_, labels_1_, labels_2_):\n",
        "        logits = self.model(images)\n",
        "        loss = loss_fn(labels, logits)\n",
        "        # Update the metric.\n",
        "        epoch_loss_metric.update_state(loss)\n",
        "\n",
        "    @staticmethod\n",
        "    def fit_cv(comp_hp: dict, model_hp: dict, model: 'ComboModel', splits_num: int = 10) -> list:\n",
        "        model_keras = model.build(model_hp)\n",
        "\n",
        "        model_keras.compile(optimizer=keras.optimizers.SGD(learning_rate=0.0001),\n",
        "                            loss=ComboModelTuner.custom_loss_mae,\n",
        "                            loss_weights=1.0,\n",
        "                            metrics=[ComboModelTuner.custom_loss_mse])\n",
        "\n",
        "        mae_per_fold_tr, mse_per_fold_tr = [], []\n",
        "        mae_per_fold_vd, mse_per_fold_vd = [], []\n",
        "\n",
        "        kfold = KFold(n_splits=splits_num, shuffle=True)\n",
        "        for j, (tr_idx, val_idx) in enumerate(kfold.split(model.features_train, model.data_train, model.labels_train)):\n",
        "            model_keras.fit(x=[model.data_train[tr_idx], model.features_train[tr_idx]],\n",
        "                            y=model.labels_train[tr_idx],\n",
        "                            batch_size=total_hp[\"batch_size_ll\"],\n",
        "                            epochs=total_hp[\"num_epochs_ll\"])\n",
        "\n",
        "            scores = model_keras.evaluate(x=[model.data_train[tr_idx], model.features_train[tr_idx]],\n",
        "                                          y=model.labels_train[tr_idx])\n",
        "\n",
        "            mse_per_fold_tr.append(scores[0])\n",
        "            mae_per_fold_tr.append(scores[1])\n",
        "\n",
        "            scores = model_keras.evaluate(x=[model.data_train[val_idx], model.features_train[val_idx]],\n",
        "                                          y=model.labels_train[val_idx])\n",
        "\n",
        "            mse_per_fold_vd.append(scores[0])\n",
        "            mae_per_fold_vd.append(scores[1])\n",
        "            print(f\"Fold #{j + 1} finished succesfully\")\n",
        "\n",
        "        return [mae_per_fold_tr, mse_per_fold_tr, mae_per_fold_vd, mse_per_fold_vd]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2tXgRld2Sie"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class SimpleCNNModel:\n",
        "    n_epochs: int = 20\n",
        "    n_row: int = 200\n",
        "    n_col: int = 200\n",
        "    input_channels: int = 1\n",
        "    random_seed: int = 1234567890\n",
        "    n_dict_features: int = 30\n",
        "    n_trait: int = 2\n",
        "\n",
        "    data_train: np.ndarray = np.ndarray([])\n",
        "    features_train: np.ndarray = np.asarray([])\n",
        "    labels_train: np.ndarray = np.ndarray([])\n",
        "\n",
        "    data_test: np.ndarray = np.asarray([])\n",
        "    features_test: np.ndarray = np.asarray([])\n",
        "    labels_test: np.ndarray = np.asarray([])\n",
        "\n",
        "    def build(self, hp: dict):\n",
        "        \"\"\"\n",
        "        Функция построения модели нейросети с функциональным интерфейсом keras\n",
        "\n",
        "        :param hp: набор гиперпараметров, отвечающих за конфигурация нейросети\n",
        "        :return: граф-представление нейросети\n",
        "        \"\"\"\n",
        "\n",
        "        inp_node = Input((self.n_row, self.n_col, self.input_channels), name=\"img_input\")\n",
        "\n",
        "        inp_node_dict = Input({self.n_dict_features}, name=\"dict_input\")\n",
        "\n",
        "        conv_node_1 = Conv2D(hp['first_conv2d_out_channels'],\n",
        "                             kernel_size=(hp['first_conv2d_kernel_size'], hp['first_conv2d_kernel_size']),\n",
        "                             padding='same',\n",
        "                             strides=(1, 1),\n",
        "                             activation=hp['first_conv2d_activation'], name=\"conv_map_1\")(inp_node)\n",
        "        if hp['need_extra_conv2d']:\n",
        "            conv_node_1 = Conv2D(hp['extra_conv2d_out_channels'],\n",
        "                                 kernel_size=(hp['extra_conv2d_kernel_size'], hp['extra_conv2d_kernel_size']),\n",
        "                                 padding='same',\n",
        "                                 strides=(1, 1),\n",
        "                                 activation=hp['extra_conv2d_activation'], name=\"conv_map_extra\")(conv_node_1)\n",
        "\n",
        "        if hp['need_batch_norm_after_first_conv2d']:\n",
        "            batch_node_1 = BatchNormalization()(conv_node_1)\n",
        "            mp_node_1 = MaxPooling2D(pool_size=(2, 2))(batch_node_1)\n",
        "        else:\n",
        "            mp_node_1 = MaxPooling2D(pool_size=(2, 2))(conv_node_1)\n",
        "\n",
        "        conv_node_2 = Conv2D(hp['second_conv2d_out_channels'],\n",
        "                             kernel_size=(hp['second_conv2d_kernel_size'], hp['second_conv2d_kernel_size']),\n",
        "                             padding='same',\n",
        "                             strides=(1, 1),\n",
        "                             activation=hp['second_conv2d_activation'], name=\"conv_map_2\")(mp_node_1)\n",
        "\n",
        "        if hp['need_batch_norm_after_second_conv2d']:\n",
        "            batch_node_2 = BatchNormalization()(conv_node_2)\n",
        "            mp_node_2 = MaxPooling2D(pool_size=(2, 2), name=\"max_pool_map\")(batch_node_2)\n",
        "        else:\n",
        "            mp_node_2 = MaxPooling2D(pool_size=(2, 2), name=\"max_pool_map\")(conv_node_2)\n",
        "\n",
        "        if hp['need_deconv_block']:\n",
        "            deconv_node_2 = Conv2DTranspose(\n",
        "                hp['second_conv2d_out_channels'],\n",
        "                kernel_size=(hp['second_conv2d_kernel_size'], hp['second_conv2d_kernel_size']),\n",
        "                padding='same',\n",
        "                strides=(2, 2),\n",
        "                activation=hp['second_conv2d_activation'],\n",
        "                name=\"deconv_2\"\n",
        "            )(mp_node_2)\n",
        "            concat_node_2 = Concatenate(name=\"concat_2\", axis=3)([deconv_node_2, conv_node_2])\n",
        "            conv_node_deconv_2 = Conv2D(\n",
        "                hp['second_conv2d_out_channels'],\n",
        "                kernel_size=(hp['second_conv2d_kernel_size'], hp['second_conv2d_kernel_size']),\n",
        "                padding='same',\n",
        "                strides=(1, 1),\n",
        "                activation=hp['second_conv2d_activation'],\n",
        "                name=\"conv_deconv_2\"\n",
        "            )(concat_node_2)\n",
        "            deconv_node_1 = Conv2DTranspose(\n",
        "                hp['first_conv2d_out_channels'],\n",
        "                kernel_size=(hp['first_conv2d_kernel_size'], hp['first_conv2d_kernel_size']),\n",
        "                padding='same',\n",
        "                strides=(2, 2),\n",
        "                activation=hp['first_conv2d_activation'],\n",
        "                name=\"deconv_1\"\n",
        "            )(conv_node_deconv_2)\n",
        "            concat_node_1 = Concatenate(name=\"concat_1\", axis=3)([deconv_node_1, conv_node_1])\n",
        "            mp_node_2 = Conv2D(\n",
        "                hp['first_conv2d_out_channels'],\n",
        "                kernel_size=(hp['first_conv2d_kernel_size'], hp['first_conv2d_kernel_size']),\n",
        "                padding='same',\n",
        "                strides=(1, 1),\n",
        "                activation=hp['first_conv2d_activation'],\n",
        "                name=\"conv_deconv_1\"\n",
        "            )(concat_node_1)\n",
        "\n",
        "        if hp['use_gap_1_or_flatten_0'] == 0:\n",
        "            flatten_node = Flatten(name='flatten')(mp_node_2)\n",
        "            dense_node = Dense(hp['num_feature_output'], activation=hp['dense_output_activation'],\n",
        "                               name=\"img_feature_output\")(flatten_node)\n",
        "        elif hp['use_gap_1_or_flatten_0'] == 1:\n",
        "            dense_node = GlobalAveragePooling2D(name=\"img_feature_output\")(mp_node_2)\n",
        "\n",
        "        concatenate_features = Concatenate(name=\"concat_features\")([inp_node_dict, dense_node])\n",
        "\n",
        "        out = Dense(self.n_trait, activation='linear', name=\"cnn_multioutput\")(concatenate_features)\n",
        "\n",
        "        model = Model(inputs=[inp_node, inp_node_dict], outputs=out, name=\"regression_model\")\n",
        "\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjUvQz9x2OgG"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "class ComboModelTuner:\n",
        "\n",
        "    @staticmethod\n",
        "    @tf.function\n",
        "    def custom_loss_mae(y_true: np.ndarray, y_pred: np.ndarray) -> np.array:\n",
        "        error = y_true - y_pred\n",
        "        abs_error_1, abs_error_2 = tf.abs(error[:, 0]), tf.abs(error[:, 1])\n",
        "        result_1, result_2 = tf.reduce_mean(abs_error_1), tf.reduce_mean(abs_error_2)\n",
        "        # return np.array([result_1, result_2])\n",
        "\n",
        "        return (result_1 + result_2) / 2\n",
        "\n",
        "    @staticmethod\n",
        "    @tf.function\n",
        "    def custom_loss_mse(y_true: np.ndarray, y_pred: np.ndarray) -> np.array:\n",
        "        error = y_true - y_pred\n",
        "        squared_error_1, squared_error_2 = tf.square(error), tf.square(error[:, 1])\n",
        "        result_1, result_2 = tf.reduce_mean(squared_error_1), tf.reduce_mean(squared_error_2)\n",
        "        # return np.array([result_1, result_2])\n",
        "        return (result_1 + result_2) / 2\n",
        "\n",
        "    @staticmethod\n",
        "    def custom_cv(total_hp: dict, cnn_hp: dict, model: 'SimpleCNNModel', splits_num: int = 10) -> list:\n",
        "        model_keras = model.build(cnn_hp)\n",
        "\n",
        "        model_keras.compile(optimizer=keras.optimizers.SGD(learning_rate=0.0001),\n",
        "                            loss=ComboModelTuner.custom_loss_mae,\n",
        "                            loss_weights=1.0,\n",
        "                            metrics=[ComboModelTuner.custom_loss_mse])\n",
        "\n",
        "        mae_per_fold_tr, mse_per_fold_tr = [], []\n",
        "        mae_per_fold_vd, mse_per_fold_vd = [], []\n",
        "\n",
        "        kfold = KFold(n_splits=splits_num, shuffle=True)\n",
        "        for j, (tr_idx, val_idx) in enumerate(kfold.split(model.features_train, model.data_train, model.labels_train)):\n",
        "            model_keras.fit(x=[model.data_train[val_idx], model.features_train[val_idx]],\n",
        "                            y=model.labels_train[val_idx],\n",
        "                            batch_size=total_hp[\"batch_size_ll\"],\n",
        "                            epochs=total_hp[\"num_epochs_ll\"])\n",
        "\n",
        "            scores = model_keras.evaluate(x=[model.data_train[tr_idx], model.features_train[tr_idx]],\n",
        "                                          y=model.labels_train[tr_idx])\n",
        "\n",
        "            mse_per_fold_tr.append(scores[0])\n",
        "            mae_per_fold_tr.append(scores[1])\n",
        "\n",
        "            scores = model_keras.evaluate(x=[model.data_train[val_idx], model.features_train[val_idx]],\n",
        "                                          y=model.labels_train[val_idx])\n",
        "\n",
        "            mse_per_fold_vd.append(scores[0])\n",
        "            mae_per_fold_vd.append(scores[1])\n",
        "            print(f\"Fold #{j + 1} finished succesfully\")\n",
        "\n",
        "        return [mae_per_fold_tr, mse_per_fold_tr, mae_per_fold_vd, mse_per_fold_vd]\n",
        "\n",
        "    @staticmethod\n",
        "    def fit_cv(total_hp: dict, cnn_hp: dict, model: 'SimpleCNNModel', splits_num: int = 10) -> list:\n",
        "        model_keras = model.build(cnn_hp)\n",
        "\n",
        "        model_keras.compile(optimizer=keras.optimizers.SGD(learning_rate=0.0001),\n",
        "                            loss=ComboModelTuner.custom_loss_mae,\n",
        "                            loss_weights=1.0,\n",
        "                            metrics=[ComboModelTuner.custom_loss_mse])\n",
        "\n",
        "        mae_per_fold_tr, mse_per_fold_tr = [], []\n",
        "        mae_per_fold_vd, mse_per_fold_vd = [], []\n",
        "\n",
        "        kfold = KFold(n_splits=splits_num, shuffle=True)\n",
        "        for j, (tr_idx, val_idx) in enumerate(kfold.split(model.features_train, model.data_train, model.labels_train)):\n",
        "            model_keras.fit(x=[model.data_train[tr_idx], model.features_train[tr_idx]],\n",
        "                            y=model.labels_train[tr_idx],\n",
        "                            batch_size=total_hp[\"batch_size_ll\"],\n",
        "                            epochs=total_hp[\"num_epochs_ll\"])\n",
        "\n",
        "            scores = model_keras.evaluate(x=[model.data_train[tr_idx], model.features_train[tr_idx]],\n",
        "                                          y=model.labels_train[tr_idx])\n",
        "\n",
        "            mse_per_fold_tr.append(scores[0])\n",
        "            mae_per_fold_tr.append(scores[1])\n",
        "\n",
        "            scores = model_keras.evaluate(x=[model.data_train[val_idx], model.features_train[val_idx]],\n",
        "                                          y=model.labels_train[val_idx])\n",
        "\n",
        "            mse_per_fold_vd.append(scores[0])\n",
        "            mae_per_fold_vd.append(scores[1])\n",
        "            print(f\"Fold #{j + 1} finished succesfully\")\n",
        "\n",
        "        return [mae_per_fold_tr, mse_per_fold_tr, mae_per_fold_vd, mse_per_fold_vd]\n",
        "\n",
        "    @staticmethod\n",
        "    def random_hyper_tuning(iters_num: int, hps_cnn: dict,\n",
        "                            train_images_: np.ndarray, train_features_: np.ndarray, train_labels_: np.ndarray,\n",
        "                            test_images_: np.ndarray, test_features_: np.ndarray, test_labels_: np.ndarray):\n",
        "\n",
        "        valid_mae_label_1, valid_mae_label_2 = [], []\n",
        "        valid_mse_label_1, valid_mse_label_2 = [], []\n",
        "        valid_accuracy_label_1, valid_accuracy_label_2 = [], []\n",
        "\n",
        "        for iter_ in range(iters_num):\n",
        "            # Сборка комбинации случайных гиперпараметров в заданын границах\n",
        "            print(f\"Random Tuning iter #{iter_} started\")\n",
        "\n",
        "            cnn_hp_comb = {}\n",
        "\n",
        "            for param in hps_cnn:\n",
        "                if len(hps_cnn[param]) > 1:\n",
        "                    if any(isinstance(x, bool) for x in hps_cnn[param]) or \\\n",
        "                            any(isinstance(x, str) for x in hps_cnn[param]):\n",
        "                        cnn_hp_comb[param] = hps_cnn[param][np.random.randint(len(hps_cnn[param]))]\n",
        "                    else:\n",
        "                        cnn_hp_comb[param] = np.random.randint(low=min(hps_cnn[param]), high=max(hps_cnn[param]))\n",
        "                else:\n",
        "                    cnn_hp_comb[param] = hps_cnn[param][0]\n",
        "\n",
        "            print(cnn_hp_comb)\n",
        "\n",
        "            model = SimpleCNNModel(n_epochs=20,\n",
        "                                   n_row=200,\n",
        "                                   n_col=200,\n",
        "                                   input_channels=1,\n",
        "                                   random_seed=1234567890,\n",
        "                                   n_dict_features=30,\n",
        "                                   n_trait=2,\n",
        "                                   data_train=train_images_,\n",
        "                                   labels_train=train_labels_,\n",
        "                                   features_train=train_features_,\n",
        "                                   data_test=test_images_,\n",
        "                                   features_test=test_features_,\n",
        "                                   labels_test=test_labels_)\n",
        "\n",
        "            # model = SimpleCNNModel()\n",
        "            metrics = ComboModelTuner.fit_cv(total_hp={\"batch_size_ll\": 64, \"num_epochs_ll\": 20},\n",
        "                                             cnn_hp=cnn_hp_comb,\n",
        "                                             model=model)\n",
        "\n",
        "            # считаем ошибку модели на тестовой выборке\n",
        "            print(f\"Random Tuning iter #{iter_} finished successfully\")\n",
        "\n",
        "    @staticmethod\n",
        "    def grid_hyper_tuning(model: 'SimpleCNNModel', hps_cnn: dict, hps_reg: dict):\n",
        "        cnn_hp_combos = itertools.product(*hps_cnn)\n",
        "        reg_hp_combos = itertools.product(*hps_reg)\n",
        "\n",
        "        valid_mae_label_1, valid_mae_label_2 = [], []\n",
        "        valid_mse_label_1, valid_mse_label_2 = [], []\n",
        "        valid_accuracy_label_1, valid_accuracy_label_2 = [], []\n",
        "\n",
        "        for i, tmp_hps_cnn in enumerate(cnn_hp_combos):\n",
        "            for j, tmp_hps_reg in enumerate(reg_hp_combos):\n",
        "                model.fit(dict(tmp_hps_cnn), dict(tmp_hps_reg))\n",
        "\n",
        "                # считаем ошибку модели на тестовой выборке\n",
        "                valid_predict = model.predict\n",
        "                print(f\"Grid Tuning iter #{i * len(reg_hp_combos) + j} finished successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JU2Uemr52HkI"
      },
      "outputs": [],
      "source": [
        "# делим данные на обучение/валидацию/тест\n",
        "test_percentage = 0.1\n",
        "test_indices = np.random.choice(images.shape[0], int(images.shape[0] * test_percentage))\n",
        "train_indices = np.setdiff1d(np.array(list(range(images.shape[0]))), test_indices)\n",
        "\n",
        "train_images, train_labels, train_dict = images[train_indices], labels[train_indices], pca_features_[train_indices]\n",
        "test_images, test_labels, test_dict = images[test_indices], labels[test_indices], pca_features_[test_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "FzfGemud2HsX",
        "outputId": "533c863b-56fe-4576-fd29-53eee5fed5bf"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'ComboModelTuner' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f89af2011f45>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         }\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m ComboModelTuner.random_hyper_tuning(10, model_hp,\n\u001b[0m\u001b[1;32m     23\u001b[0m                                     \u001b[0mtrain_images_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                                     \u001b[0mtrain_labels_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ComboModelTuner' is not defined"
          ]
        }
      ],
      "source": [
        "# задаем сетку гиперпараметров для\n",
        "\n",
        "model_hp = {# сначала идут параметры сверточной части модели\n",
        "            'first_conv2d_out_channels': [32, 64],\n",
        "            'first_conv2d_kernel_size': [3, 5, 7],\n",
        "            'first_conv2d_activation': ['tanh', 'relu'],\n",
        "            'need_extra_conv2d': [False, True],\n",
        "            'extra_conv2d_out_channels': [32, 64],\n",
        "            'extra_conv2d_kernel_size': [3, 5, 7],\n",
        "            'extra_conv2d_activation': ['tanh', 'relu'],\n",
        "            'need_batch_norm_after_first_conv2d': [True, False],\n",
        "            'second_conv2d_kernel_size': [3, 5],\n",
        "            'second_conv2d_out_channels': [64, 128],\n",
        "            'second_conv2d_activation': ['tanh', 'relu'],\n",
        "            'need_batch_norm_after_second_conv2d': [True, False],\n",
        "            'dense_output_activation': ['sigmoid', 'linear'],\n",
        "            'use_gap_1_or_flatten_0': [1, 0],\n",
        "            'need_deconv_block': [False, True],\n",
        "            'num_feature_output': [64, 128, 256],\n",
        "        }\n",
        "\n",
        "ComboModelTuner.random_hyper_tuning(10, model_hp,\n",
        "                                    train_images_=train_images,\n",
        "                                    train_labels_=train_labels,\n",
        "                                    train_features_=train_dict,\n",
        "                                    test_images_=test_images,\n",
        "                                    test_labels_=test_labels,\n",
        "                                    test_features_=test_dict)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}