{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqeQ0cHQnCbv",
        "outputId": "1b30a34a-cdeb-48f7-e9d4-d79ad8e631ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_decision_forests in /usr/local/lib/python3.10/dist-packages (1.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (2.0.3)\n",
            "Requirement already satisfied: tensorflow~=2.16.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (2.16.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.16.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.4.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (0.43.0)\n",
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (3.1.0)\n",
            "Requirement already satisfied: tf-keras~=2.16 in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (2.16.0)\n",
            "Requirement already satisfied: ydf in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (0.4.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (4.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (1.64.0)\n",
            "Requirement already satisfied: tensorboard<2.17,>=2.16 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (2.16.2)\n",
            "Requirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (3.3.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tensorflow_decision_forests) (0.37.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2024.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow~=2.16.1->tensorflow_decision_forests) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow~=2.16.1->tensorflow_decision_forests) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow~=2.16.1->tensorflow_decision_forests) (0.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow~=2.16.1->tensorflow_decision_forests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow~=2.16.1->tensorflow_decision_forests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow~=2.16.1->tensorflow_decision_forests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow~=2.16.1->tensorflow_decision_forests) (2024.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow~=2.16.1->tensorflow_decision_forests) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow~=2.16.1->tensorflow_decision_forests) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow~=2.16.1->tensorflow_decision_forests) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow~=2.16.1->tensorflow_decision_forests) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow~=2.16.1->tensorflow_decision_forests) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow~=2.16.1->tensorflow_decision_forests) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow~=2.16.1->tensorflow_decision_forests) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_decision_forests\n",
        "# !pip install numpy\n",
        "# !pip install pandas\n",
        "# !pip install keras\n",
        "# !pip install scikit-learn\n",
        "# !pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DF36u6uEwBMB"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Sequential, Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import Resizing\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow_decision_forests as tfdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rE7GAxmts9cC"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "def pca_features(data: np.ndarray, n_components: int = 10) -> np.ndarray:\n",
        "    flattened_data = np.array([img.flatten() for img in data])\n",
        "    data_processed = PCA(n_components=n_components).fit_transform(flattened_data)\n",
        "    return data_processed\n",
        "\n",
        "\n",
        "def t_sne_features(data: np.ndarray, n_components: int = 10):\n",
        "    data_embeded = TSNE(n_components=n_components,\n",
        "                        learning_rate='auto',\n",
        "                        init='random',\n",
        "                        method='exact',\n",
        "                        perplexity=3).fit_transform(data)\n",
        "    print(data_embeded.shape)\n",
        "    return data_embeded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EAlpGeePtNK0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2 as cv\n",
        "import pandas as pd\n",
        "\n",
        "def load_images_from_folder(folder: str) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Функция подгрузки необходимого набора искусственных изображений из передаваемого каталога.\n",
        "\n",
        "    :param folder: папка с изображениями, сохраненными в формате .png\n",
        "\n",
        "    :return: список формата Numpy, содержащие AIO в объектах класса Image из Pillow\n",
        "    \"\"\"\n",
        "\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = cv.imread(os.path.join(folder, filename), cv.IMREAD_GRAYSCALE)\n",
        "        if img is not None:\n",
        "            images.append(np.asarray(img).astype(np.float32))\n",
        "    return np.asarray(images)\n",
        "\n",
        "folder_images = \"/content\"\n",
        "images = load_images_from_folder(folder_images)\n",
        "pca_features_ = pca_features(images, n_components=30)\n",
        "df_wheat = pd.read_csv(\"/content/wheat_pheno_num_sync.csv\")\n",
        "labels = df_wheat[[\"Урожайность.зерна..г.\", \"Высота.растений..см\"]].to_numpy()\n",
        "\n",
        "# импутирование данных\n",
        "# (Пока просто средними значениями) импутируем данные, поскольку присутствуют пропуски\n",
        "# imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imp = KNNImputer(n_neighbors=2, weights='uniform')\n",
        "labels = imp.fit_transform(labels.reshape(-1, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sy6suYiw6hI"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "# Модель, скомбинированная со случайным лесом\n",
        "@dataclass\n",
        "class ComboModel:\n",
        "\n",
        "    n_epochs: int = 100\n",
        "    n_row: int = 200\n",
        "    n_col: int = 200\n",
        "    input_channels: int = 1\n",
        "    n_data: int = 100  # len(aio_labels)\n",
        "    random_seed: int = 1234567890\n",
        "    n_dict_features: int = 30\n",
        "    n_trait: int = 1\n",
        "    data_train: np.ndarray = np.ndarray([])\n",
        "    label_train: np.ndarray = np.ndarray([])\n",
        "\n",
        "    optimizer: keras.optimizers.Optimizer = None\n",
        "    model: keras.models.Model = None\n",
        "\n",
        "    def combo_model_functional(self, hp):\n",
        "        \"\"\"\n",
        "        Функция построения модели нейросети с функциональным интерфейсом keras\n",
        "\n",
        "        :param hp: набор гиперпараметров, отвечающих за конфигурация нейросети\n",
        "        :return: граф-представление нейросети\n",
        "        \"\"\"\n",
        "\n",
        "        inp_node = Input((self.n_row, self.n_col, self.input_channels), name=\"img_input\")\n",
        "        inp_dict_model = Input(self.n_dict_features, name=\"pop_struct_input\")\n",
        "\n",
        "        conv_node_1 = Conv2D(hp['first_conv2d_out_channels'],\n",
        "                             kernel_size=(hp['first_conv2d_kernel_size'], hp['first_conv2d_kernel_size']),\n",
        "                             padding='same',\n",
        "                             strides=(1, 1),\n",
        "                             activation=hp['first_conv2d_activation'], name=\"conv_map_1\")(inp_node)\n",
        "        if hp['need_extra_conv2d']:\n",
        "            conv_node_1 = Conv2D(hp['extra_conv2d_out_channels'],\n",
        "                                 kernel_size=(hp['extra_conv2d_kernel_size'], hp['extra_conv2d_kernel_size']),\n",
        "                                 padding='same',\n",
        "                                 strides=(1, 1),\n",
        "                                 activation=hp['extra_conv2d_activation'], name=\"conv_map_extra\")(conv_node_1)\n",
        "\n",
        "        if hp['need_batch_norm_after_first_conv2d']:\n",
        "            batch_node_1 = BatchNormalization()(conv_node_1)\n",
        "            mp_node_1 = MaxPooling2D(pool_size=(2, 2))(batch_node_1)\n",
        "        else:\n",
        "            mp_node_1 = MaxPooling2D(pool_size=(2, 2))(conv_node_1)\n",
        "\n",
        "        conv_node_2 = Conv2D(hp['second_conv2d_out_channels'],\n",
        "                             kernel_size=(hp['second_conv2d_kernel_size'], hp['second_conv2d_kernel_size']),\n",
        "                             padding='same',\n",
        "                             strides=(1, 1),\n",
        "                             activation=hp['second_conv2d_activation'], name=\"conv_map_2\")(mp_node_1)\n",
        "\n",
        "        if hp['need_batch_norm_after_second_conv2d']:\n",
        "            batch_node_2 = BatchNormalization()(conv_node_2)\n",
        "            mp_node_2 = MaxPooling2D(pool_size=(2, 2), name=\"max_pool_map\")(batch_node_2)\n",
        "        else:\n",
        "            mp_node_2 = MaxPooling2D(pool_size=(2, 2), name=\"max_pool_map\")(conv_node_2)\n",
        "\n",
        "        if hp['need_deconv_block']:\n",
        "            deconv_node_2 = Conv2DTranspose(\n",
        "                hp['second_conv2d_out_channels'],\n",
        "                kernel_size=(hp['second_conv2d_kernel_size'], hp['second_conv2d_kernel_size']),\n",
        "                padding='same',\n",
        "                strides=(2, 2),\n",
        "                activation=hp['second_conv2d_activation'],\n",
        "                name=\"deconv_2\"\n",
        "            )(mp_node_2)\n",
        "            concat_node_2 = Concatenate(name=\"concat_2\", axis=3)([deconv_node_2, conv_node_2])\n",
        "            conv_node_deconv_2 = Conv2D(\n",
        "                hp['second_conv2d_out_channels'],\n",
        "                kernel_size=(hp['second_conv2d_kernel_size'], hp['second_conv2d_kernel_size']),\n",
        "                padding='same',\n",
        "                strides=(1, 1),\n",
        "                activation=hp['second_conv2d_activation'],\n",
        "                name=\"conv_deconv_2\"\n",
        "            )(concat_node_2)\n",
        "            deconv_node_1 = Conv2DTranspose(\n",
        "                hp['first_conv2d_out_channels'],\n",
        "                kernel_size=(hp['first_conv2d_kernel_size'], hp['first_conv2d_kernel_size']),\n",
        "                padding='same',\n",
        "                strides=(2, 2),\n",
        "                activation=hp['first_conv2d_activation'],\n",
        "                name=\"deconv_1\"\n",
        "            )(conv_node_deconv_2)\n",
        "            concat_node_1 = Concatenate(name=\"concat_1\", axis=3)([deconv_node_1, conv_node_1])\n",
        "            mp_node_2 = Conv2D(\n",
        "                hp['first_conv2d_out_channels'],\n",
        "                kernel_size=(hp['first_conv2d_kernel_size'], hp['first_conv2d_kernel_size']),\n",
        "                padding='same',\n",
        "                strides=(1, 1),\n",
        "                activation=hp['first_conv2d_activation'],\n",
        "                name=\"conv_deconv_1\"\n",
        "            )(concat_node_1)\n",
        "\n",
        "        if hp['use_gap_1_or_flatten_0'] == 0:\n",
        "            flatten_node = Flatten(name='flatten')(mp_node_2)\n",
        "            dense_node = Dense(hp['num_feature_output'], activation=hp['dense_output_activation'],\n",
        "                               name=\"img_feature_output\")(flatten_node)\n",
        "        elif hp['use_gap_1_or_flatten_0'] == 1:\n",
        "            dense_node = GlobalAveragePooling2D(name=\"img_feature_output\")(mp_node_2)\n",
        "\n",
        "        concatenate_features = Concatenate(name=\"concat_features\")(inp_dict_model, dense_node)\n",
        "\n",
        "        reg_forest_1 = tfdf.keras.RandomForestModel(task=tfdf.keras.Task.REGRESSION,\n",
        "                                                    num_trees=hp['num_estimators'],\n",
        "                                                    max_depth=hp['max_depth'],\n",
        "                                                    bootstrap_training_dataset=hp['bootstrap'])\n",
        "        forest_1_pred = reg_forest_1(concatenate_features)\n",
        "\n",
        "        reg_forest_2 = tfdf.keras.RandomForestModel(task=tfdf.keras.Task.REGRESSION,\n",
        "                                                    num_trees=hp['num_estimators'],\n",
        "                                                    max_depth=hp['max_depth'],\n",
        "                                                    bootstrap_training_dataset=hp['bootstrap'])\n",
        "        forest_2_pred = reg_forest_2(concatenate_features)\n",
        "\n",
        "        combo_model = Model(inputs=[inp_node, inp_dict_model], outputs=[forest_1_pred, forest_2_pred],\n",
        "                            name=\"feature_model\")\n",
        "\n",
        "        self.model = combo_model\n",
        "\n",
        "    def build(self, hp):\n",
        "        \"\"\"\n",
        "        Builds a convolutional model.\n",
        "        \"\"\"\n",
        "        # Гиперпараметры сверточной части модели\n",
        "        model_hp = {\n",
        "            # сначала идут параметры сверточной части модели\n",
        "            'first_conv2d_out_channels': [32, 64],\n",
        "            'first_conv2d_kernel_size': [3, 5, 7],\n",
        "            'first_conv2d_activation': ['tanh', 'relu'],\n",
        "            'need_extra_conv2d': [False, True],\n",
        "            'extra_conv2d_out_channels': [32, 64],\n",
        "            'extra_conv2d_kernel_size': [3, 5, 7],\n",
        "            'extra_conv2d_activation': ['tanh', 'relu'],\n",
        "            'need_batch_norm_after_first_conv2d': [True, False],\n",
        "            'second_conv2d_kernel_size': [3, 5],\n",
        "            'second_conv2d_out_channels': [128, 64],\n",
        "            'second_conv2d_activation': ['tanh', 'relu'],\n",
        "            'need_batch_norm_after_second_conv2d': [True, False],\n",
        "            'dense_output_activation': ['sigmoid', 'linear'],\n",
        "            'use_gap_1_or_flatten_0': [1, 0],\n",
        "            'need_deconv_block': [False, True],\n",
        "            'num_feature_output': [128, 64, 256],\n",
        "            # а дальше идут параметры регрессионного случайного леса\n",
        "            'n_estimators': [5, 20, 50, 100],\n",
        "            'max_features': ['auto', 'sqrt'],\n",
        "            'max_depth': [(i + 1) * 5 for i in range(7)],\n",
        "            'min_samples_split': [2, 6, 10],\n",
        "            'bootstrap': [True, False]\n",
        "        }\n",
        "\n",
        "        # возвращаем собранную модель\n",
        "        return self.combo_model_functional(model_hp)\n",
        "\n",
        "    @staticmethod\n",
        "    @tf.function\n",
        "    def custom_loss_mae(y_true: np.ndarray, y_pred: np.ndarray) -> np.array:\n",
        "        error = y_true - y_pred\n",
        "        abs_error_1, abs_error_2 = tf.abs(error[:, 0]), tf.abs(error[:, 1])\n",
        "        result_1, result_2 = tf.reduce_mean(abs_error_1), tf.reduce_mean(abs_error_2)\n",
        "        # return np.array([result_1, result_2])\n",
        "\n",
        "        return np.sqrt(result_1 * result_2)\n",
        "\n",
        "    @staticmethod\n",
        "    @tf.function\n",
        "    def custom_loss_mse(y_true: np.ndarray, y_pred: np.ndarray) -> np.array:\n",
        "        error = y_true - y_pred\n",
        "        squared_error_1, squared_error_2 = tf.square(error), tf.square(error[:, 1])\n",
        "        result_1, result_2 = tf.reduce_mean(squared_error_1), tf.reduce_mean(squared_error_2)\n",
        "        # return np.array([result_1, result_2])\n",
        "        return np.sqrt(result_1 * result_2)\n",
        "\n",
        "    # Function to run the train step.\n",
        "    # здесь надо подумать как исправить эту функцию\n",
        "    @tf.function\n",
        "    def run_train_step(self, images_, pop_comps_, labels_1_, labels_2_):\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits_1, logits_2 = self.model(images_, pop_comps_)\n",
        "            loss_1 = loss_fn(labels, logits_1)\n",
        "            loss_2 = loss_fn(labels, logits_2)\n",
        "            # Add any regularization losses.\n",
        "            if self.model.losses:\n",
        "                loss_1 += tf.math.add_n(self.model.losses)\n",
        "                loss_2 += tf.math.add_n(self.model.losses)\n",
        "        gradients = tape.gradient(loss_1, self.model.trainable_variables)\n",
        "        gradients = tape.gradient(loss_2, self.model.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
        "\n",
        "    # Function to run the validation step.\n",
        "    @tf.function\n",
        "    def run_val_step(self, images_, pop_comps_, labels_1_, labels_2_):\n",
        "        logits = self.model(images)\n",
        "        loss = loss_fn(labels, logits)\n",
        "        # Update the metric.\n",
        "        epoch_loss_metric.update_state(loss)\n",
        "\n",
        "    @staticmethod\n",
        "    def fit_cv(comp_hp: dict, model_hp: dict, model: 'ComboModel', splits_num: int = 10) -> list:\n",
        "        model_keras = model.build(model_hp)\n",
        "\n",
        "        model_keras.compile(optimizer=keras.optimizers.SGD(learning_rate=0.0001),\n",
        "                            loss=ComboModelTuner.custom_loss_mae,\n",
        "                            loss_weights=1.0,\n",
        "                            metrics=[ComboModelTuner.custom_loss_mse])\n",
        "\n",
        "        mae_per_fold_tr, mse_per_fold_tr = [], []\n",
        "        mae_per_fold_vd, mse_per_fold_vd = [], []\n",
        "\n",
        "        kfold = KFold(n_splits=splits_num, shuffle=True)\n",
        "        for j, (tr_idx, val_idx) in enumerate(kfold.split(model.features_train, model.data_train, model.labels_train)):\n",
        "            model_keras.fit(x=[model.data_train[tr_idx], model.features_train[tr_idx]],\n",
        "                            y=model.labels_train[tr_idx],\n",
        "                            batch_size=total_hp[\"batch_size_ll\"],\n",
        "                            epochs=total_hp[\"num_epochs_ll\"])\n",
        "\n",
        "            scores = model_keras.evaluate(x=[model.data_train[tr_idx], model.features_train[tr_idx]],\n",
        "                                          y=model.labels_train[tr_idx])\n",
        "\n",
        "            mse_per_fold_tr.append(scores[0])\n",
        "            mae_per_fold_tr.append(scores[1])\n",
        "\n",
        "            scores = model_keras.evaluate(x=[model.data_train[val_idx], model.features_train[val_idx]],\n",
        "                                          y=model.labels_train[val_idx])\n",
        "\n",
        "            mse_per_fold_vd.append(scores[0])\n",
        "            mae_per_fold_vd.append(scores[1])\n",
        "            print(f\"Fold #{j + 1} finished succesfully\")\n",
        "\n",
        "        return [mae_per_fold_tr, mse_per_fold_tr, mae_per_fold_vd, mse_per_fold_vd]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "P-WRrNLWo57I",
        "outputId": "6f99704d-cb89-4ed1-9011-02da0a70bda4"
      },
      "outputs": [
        {
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-6-fe16b81e7eef>, line 47)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-fe16b81e7eef>\"\u001b[0;36m, line \u001b[0;32m47\u001b[0m\n\u001b[0;31m    metrics = ComboModelTuner.custom_cv(total_hp={\"batch_size_ll\": 64, \"num_epochs_ll\": 30},\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ],
      "source": [
        "# обучение модели со случайным лесом\n",
        "\n",
        "def hyper_tuning(model: 'ComboModel', iters_num: int, hps_cnn: dict, hps_reg: dict):\n",
        "    valid_mae_label_1, valid_mae_label_2 = [], []\n",
        "    valid_mse_label_1, valid_mse_label_2 = [], []\n",
        "    valid_accuracy_label_1, valid_accuracy_label_2 = [], []\n",
        "\n",
        "    for iter_ in range(iters_num):\n",
        "        # Сборка комбинации случайных гиперпараметров в заданын границах\n",
        "        cnn_hp_comb, reg_hp_comb = {}, {}\n",
        "\n",
        "        for param in hps_cnn:\n",
        "            if len(hps_cnn[param]) > 1:\n",
        "                if any(isinstance(x, bool) for x in hps_cnn[param]) or any(isinstance(x, str) for x in hps_cnn[param]):\n",
        "                    cnn_hp_comb[param] = hps_cnn[param][np.random.randint(len(hps_cnn[param]))]\n",
        "                else:\n",
        "                    cnn_hp_comb[param] = np.random.randint(low=min(hps_cnn[param]), high=max(hps_cnn[param]))\n",
        "            else:\n",
        "                cnn_hp_comb[param] = hps_cnn[param][0]\n",
        "\n",
        "        for param in hps_reg:\n",
        "            if len(hps_reg[param]) > 1:\n",
        "                if any(isinstance(x, bool) for x in hps_reg[param]) or any(isinstance(x, str) for x in hps_reg[param]):\n",
        "                    reg_hp_comb[param] = hps_reg[param][np.random.randint(len(hps_reg[param]))]\n",
        "                else:\n",
        "                    reg_hp_comb[param] = np.random.randint(low=min(hps_reg[param]), high=max(hps_reg[param]))\n",
        "            else:\n",
        "                reg_hp_comb[param] = hps_reg[param][0]\n",
        "\n",
        "        print(cnn_hp_comb)\n",
        "\n",
        "        model = SimpleCNNModel(n_epochs=20,\n",
        "                               n_row=200,\n",
        "                               n_col=200,\n",
        "                               input_channels=1,\n",
        "                               random_seed=1234567890,\n",
        "                               n_dict_features=30,\n",
        "                               n_trait=2,\n",
        "                               data_train=train_images_,\n",
        "                               labels_train=train_labels_,\n",
        "                               features_train=train_features_,\n",
        "                               data_test=test_images_,\n",
        "                               features_test=test_features_,\n",
        "                               labels_test=test_labels_)\n",
        "\n",
        "            # model = SimpleCNNModel()\n",
        "          metrics = ComboModelTuner.custom_cv(total_hp={\"batch_size_ll\": 64, \"num_epochs_ll\": 30},\n",
        "                                              cnn_hp=cnn_hp_comb,\n",
        "                                              model=model)\n",
        "\n",
        "        # считаем ошибку модели на тестовой выборке\n",
        "        print(f\"Random Tuning iter #{iter_} finished successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "B2tXgRld2Sie"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "# Модель сугубо нейронной сети\n",
        "@dataclass\n",
        "class SimpleCNNModel:\n",
        "    n_epochs: int = 20\n",
        "    n_row: int = 200\n",
        "    n_col: int = 200\n",
        "    input_channels: int = 1\n",
        "    random_seed: int = 1234567890\n",
        "    n_dict_features: int = 30\n",
        "    n_trait: int = 2\n",
        "\n",
        "    data_train: np.ndarray = np.ndarray([])\n",
        "    features_train: np.ndarray = np.asarray([])\n",
        "    labels_train: np.ndarray = np.ndarray([])\n",
        "\n",
        "    data_test: np.ndarray = np.asarray([])\n",
        "    features_test: np.ndarray = np.asarray([])\n",
        "    labels_test: np.ndarray = np.asarray([])\n",
        "\n",
        "    def build(self, hp: dict):\n",
        "        \"\"\"\n",
        "        Функция построения модели нейросети с функциональным интерфейсом keras\n",
        "\n",
        "        :param hp: набор гиперпараметров, отвечающих за конфигурация нейросети\n",
        "        :return: граф-представление нейросети\n",
        "        \"\"\"\n",
        "\n",
        "        inp_node = Input((self.n_row, self.n_col, self.input_channels), name=\"img_input\")\n",
        "\n",
        "        inp_node_dict = Input({self.n_dict_features}, name=\"dict_input\")\n",
        "\n",
        "        conv_node_1 = Conv2D(hp['first_conv2d_out_channels'],\n",
        "                             kernel_size=(hp['first_conv2d_kernel_size'], hp['first_conv2d_kernel_size']),\n",
        "                             padding='same',\n",
        "                             strides=(1, 1),\n",
        "                             activation=hp['first_conv2d_activation'], name=\"conv_map_1\")(inp_node)\n",
        "        if hp['need_extra_conv2d']:\n",
        "            conv_node_1 = Conv2D(hp['extra_conv2d_out_channels'],\n",
        "                                 kernel_size=(hp['extra_conv2d_kernel_size'], hp['extra_conv2d_kernel_size']),\n",
        "                                 padding='same',\n",
        "                                 strides=(1, 1),\n",
        "                                 activation=hp['extra_conv2d_activation'], name=\"conv_map_extra\")(conv_node_1)\n",
        "\n",
        "        if hp['need_batch_norm_after_first_conv2d']:\n",
        "            batch_node_1 = BatchNormalization()(conv_node_1)\n",
        "            mp_node_1 = MaxPooling2D(pool_size=(2, 2))(batch_node_1)\n",
        "        else:\n",
        "            mp_node_1 = MaxPooling2D(pool_size=(2, 2))(conv_node_1)\n",
        "\n",
        "        conv_node_2 = Conv2D(hp['second_conv2d_out_channels'],\n",
        "                             kernel_size=(hp['second_conv2d_kernel_size'], hp['second_conv2d_kernel_size']),\n",
        "                             padding='same',\n",
        "                             strides=(1, 1),\n",
        "                             activation=hp['second_conv2d_activation'], name=\"conv_map_2\")(mp_node_1)\n",
        "\n",
        "        if hp['need_batch_norm_after_second_conv2d']:\n",
        "            batch_node_2 = BatchNormalization()(conv_node_2)\n",
        "            mp_node_2 = MaxPooling2D(pool_size=(2, 2), name=\"max_pool_map\")(batch_node_2)\n",
        "        else:\n",
        "            mp_node_2 = MaxPooling2D(pool_size=(2, 2), name=\"max_pool_map\")(conv_node_2)\n",
        "\n",
        "        if hp['need_deconv_block']:\n",
        "            deconv_node_2 = Conv2DTranspose(\n",
        "                hp['second_conv2d_out_channels'],\n",
        "                kernel_size=(hp['second_conv2d_kernel_size'], hp['second_conv2d_kernel_size']),\n",
        "                padding='same',\n",
        "                strides=(2, 2),\n",
        "                activation=hp['second_conv2d_activation'],\n",
        "                name=\"deconv_2\"\n",
        "            )(mp_node_2)\n",
        "            concat_node_2 = Concatenate(name=\"concat_2\", axis=3)([deconv_node_2, conv_node_2])\n",
        "            conv_node_deconv_2 = Conv2D(\n",
        "                hp['second_conv2d_out_channels'],\n",
        "                kernel_size=(hp['second_conv2d_kernel_size'], hp['second_conv2d_kernel_size']),\n",
        "                padding='same',\n",
        "                strides=(1, 1),\n",
        "                activation=hp['second_conv2d_activation'],\n",
        "                name=\"conv_deconv_2\"\n",
        "            )(concat_node_2)\n",
        "            deconv_node_1 = Conv2DTranspose(\n",
        "                hp['first_conv2d_out_channels'],\n",
        "                kernel_size=(hp['first_conv2d_kernel_size'], hp['first_conv2d_kernel_size']),\n",
        "                padding='same',\n",
        "                strides=(2, 2),\n",
        "                activation=hp['first_conv2d_activation'],\n",
        "                name=\"deconv_1\"\n",
        "            )(conv_node_deconv_2)\n",
        "            concat_node_1 = Concatenate(name=\"concat_1\", axis=3)([deconv_node_1, conv_node_1])\n",
        "            mp_node_2 = Conv2D(\n",
        "                hp['first_conv2d_out_channels'],\n",
        "                kernel_size=(hp['first_conv2d_kernel_size'], hp['first_conv2d_kernel_size']),\n",
        "                padding='same',\n",
        "                strides=(1, 1),\n",
        "                activation=hp['first_conv2d_activation'],\n",
        "                name=\"conv_deconv_1\"\n",
        "            )(concat_node_1)\n",
        "\n",
        "        if hp['use_gap_1_or_flatten_0'] == 0:\n",
        "            flatten_node = Flatten(name='flatten')(mp_node_2)\n",
        "            dense_node = Dense(hp['num_feature_output'], activation=hp['dense_output_activation'],\n",
        "                               name=\"img_feature_output\")(flatten_node)\n",
        "        elif hp['use_gap_1_or_flatten_0'] == 1:\n",
        "            dense_node = GlobalAveragePooling2D(name=\"img_feature_output\")(mp_node_2)\n",
        "\n",
        "        concatenate_features = Concatenate(name=\"concat_features\")([inp_node_dict, dense_node])\n",
        "\n",
        "        out = Dense(self.n_trait, activation='linear', name=\"cnn_multioutput\")(concatenate_features)\n",
        "\n",
        "        model = Model(inputs=[inp_node, inp_node_dict], outputs=out, name=\"regression_model\")\n",
        "\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Z5t8EVBx1_ZP"
      },
      "outputs": [],
      "source": [
        "class ComboDataPool(keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self, images, features, labels, batch_size: int, max_len: int = -1):\n",
        "        self.batch_size = batch_size\n",
        "        self.images = images[:max_len]\n",
        "        self.features = features[:max_len]\n",
        "        self.labels = labels[:max_len]\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(self.images.shape[0] / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_data = [self.images[idx * self.batch_size:(idx + 1) * self.batch_size],\n",
        "                   self.features[idx * self.batch_size:(idx + 1) * self.batch_size]]\n",
        "        batch_labels = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "\n",
        "        return batch_data, batch_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "bjUvQz9x2OgG"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "\n",
        "class ComboModelTuner:\n",
        "\n",
        "    @staticmethod\n",
        "    @tf.function\n",
        "    def fit_loss_mae(y_true: np.ndarray, y_pred: np.ndarray) -> np.array:\n",
        "        \"\"\"\n",
        "        MAE-функция потерь для обучения при помощи стандартного метода '.fit()'\n",
        "        \"\"\"\n",
        "        error = y_true - y_pred\n",
        "        abs_error_1, abs_error_2 = tf.abs(error[:, 0]), tf.abs(error[:, 1])\n",
        "        result_1, result_2 = tf.reduce_mean(abs_error_1), tf.reduce_mean(abs_error_2)\n",
        "        return (result_1 + result_2) / 2\n",
        "\n",
        "    @staticmethod\n",
        "    @tf.function\n",
        "    def fit_loss_mse(y_true: np.ndarray, y_pred: np.ndarray) -> np.array:\n",
        "        \"\"\"\n",
        "        MSE-функция потерь для обучения при помощи стандартного метода '.fit()'\n",
        "        \"\"\"\n",
        "        error = y_true - y_pred\n",
        "        squared_error_1, squared_error_2 = tf.square(error), tf.square(error[:, 1])\n",
        "        result_1, result_2 = tf.reduce_mean(squared_error_1), tf.reduce_mean(squared_error_2)\n",
        "        return (result_1 + result_2) / 2\n",
        "\n",
        "    @staticmethod\n",
        "    @tf.function\n",
        "    def custom_loss_mae(y_true: np.ndarray, y_pred: np.ndarray) -> np.array:\n",
        "        \"\"\"\n",
        "        MAE-функция потерь для обучения при помощи пользовательской реализации цикла обучения\n",
        "        \"\"\"\n",
        "        error = y_true - y_pred\n",
        "        abs_error_1, abs_error_2 = tf.abs(error[:, 0]), tf.abs(error[:, 1])\n",
        "        result_1, result_2 = tf.reduce_mean(abs_error_1), tf.reduce_mean(abs_error_2)\n",
        "        return (result_1 + result_2) / 2\n",
        "\n",
        "    @staticmethod\n",
        "    @tf.function\n",
        "    def custom_loss_mse(y_true: np.ndarray, y_pred: np.ndarray) -> np.array:\n",
        "        \"\"\"\n",
        "        MSE-функция потерь для обучения при помощи пользовательской реализации цикла обучения\n",
        "        \"\"\"\n",
        "        error = y_true - y_pred\n",
        "        squared_error_1, squared_error_2 = tf.square(error), tf.square(error[:, 1])\n",
        "        result_1, result_2 = tf.reduce_mean(squared_error_1), tf.reduce_mean(squared_error_2)\n",
        "        return (result_1 + result_2) / 2\n",
        "\n",
        "    @staticmethod\n",
        "    def custom_cv(total_hp: dict, cnn_hp: dict, model: 'SimpleCNNModel',\n",
        "                  splits_num: int = 10,\n",
        "                  early_stop: bool = True, model_checkpoint: bool = True,\n",
        "                  data_generator: bool = False) -> list:\n",
        "        model_keras = model.build(cnn_hp)\n",
        "\n",
        "        learning_data_pool = ComboDataPool(images=train_images,\n",
        "                                           features=train_dict,\n",
        "                                           labels=train_labels,\n",
        "                                           batch_size=64)\n",
        "\n",
        "        callbacks = []\n",
        "        if early_stop:\n",
        "            callback_early_stop = EarlyStopping(monitor=\"loss\", min_delta=0.001, patience=2, verbose=1)\n",
        "            callbacks.append(callback_early_stop)\n",
        "        if model_checkpoint:\n",
        "            callback_checkpoint = ModelCheckpoint(filepath=\"checkpoints/model_no_df_{epoch}.keras\",\n",
        "                                                  save_best_only=True, monitor=\"loss\", verbose=1)\n",
        "            callbacks.append(callback_checkpoint)\n",
        "\n",
        "        model_keras.compile(optimizer=keras.optimizers.SGD(learning_rate=0.001),\n",
        "                            loss=ComboModelTuner.fit_loss_mae,\n",
        "                            metrics=[ComboModelTuner.fit_loss_mse])\n",
        "\n",
        "        learning_data_pool = ComboDataPool(images=train_images,\n",
        "                                           features=train_dict,\n",
        "                                           labels=train_labels,\n",
        "                                           batch_size=64)\n",
        "\n",
        "        mae_per_fold_tr, mse_per_fold_tr = [], []\n",
        "        mae_per_fold_vd, mse_per_fold_vd = [], []\n",
        "\n",
        "        kfold = KFold(n_splits=splits_num, shuffle=True)\n",
        "        for j, (tr_idx, val_idx) in enumerate(kfold.split(model.features_train, model.data_train, model.labels_train)):\n",
        "            if data_generator:\n",
        "                history = model_keras.fit(learning_data_pool, epochs=total_hp[\"num_epochs_ll\"],\n",
        "                                      validation_data=([model.data_train[val_idx], model.features_train[val_idx]],\n",
        "                                                      model.labels_train[val_idx]))\n",
        "            else:\n",
        "                history = model_keras.fit(x=[model.data_train[tr_idx], model.features_train[tr_idx]],\n",
        "                                          y=model.labels_train[tr_idx],\n",
        "                                          batch_size=total_hp[\"batch_size_ll\"],\n",
        "                                          epochs=total_hp[\"num_epochs_ll\"],\n",
        "                                          validation_data=([model.data_train[val_idx], model.features_train[val_idx]],\n",
        "                                                          model.labels_train[val_idx]),\n",
        "                                          callbacks=callbacks)\n",
        "\n",
        "            scores = model_keras.evaluate(x=[model.data_train[tr_idx], model.features_train[tr_idx]],\n",
        "                                          y=model.labels_train[tr_idx])\n",
        "\n",
        "            mse_per_fold_tr.append(scores[0])\n",
        "            mae_per_fold_tr.append(scores[1])\n",
        "\n",
        "            scores = model_keras.evaluate(x=[model.data_train[val_idx], model.features_train[val_idx]],\n",
        "                                          y=model.labels_train[val_idx])\n",
        "\n",
        "            mse_per_fold_vd.append(scores[0])\n",
        "            mae_per_fold_vd.append(scores[1])\n",
        "            print(f\"Fold #{j + 1} finished succesfully\")\n",
        "\n",
        "        return [mae_per_fold_tr, mse_per_fold_tr, mae_per_fold_vd, mse_per_fold_vd]\n",
        "\n",
        "    @staticmethod\n",
        "    def fit_cv(total_hp: dict, cnn_hp: dict, model: 'SimpleCNNModel',\n",
        "               splits_num: int = 10,\n",
        "               early_stop: bool = True, model_checkpoint: bool = True,\n",
        "               data_generator: bool = False) -> list:\n",
        "        model_keras = model.build(cnn_hp)\n",
        "\n",
        "        learning_data_pool = ComboDataPool(images=train_images,\n",
        "                                           features=train_dict,\n",
        "                                           labels=train_labels,\n",
        "                                           batch_size=64)\n",
        "\n",
        "        callbacks = []\n",
        "        if early_stop:\n",
        "            callback_early_stop = EarlyStopping(monitor=\"loss\", min_delta=0.001, patience=2, verbose=1)\n",
        "            callbacks.append(callback_early_stop)\n",
        "        if model_checkpoint:\n",
        "            callback_checkpoint = ModelCheckpoint(filepath=\"checkpoints/model_no_df_{epoch}.keras\",\n",
        "                                                  save_best_only=True, monitor=\"loss\", verbose=1)\n",
        "            callbacks.append(callback_checkpoint)\n",
        "\n",
        "        model_keras.compile(optimizer=keras.optimizers.SGD(learning_rate=0.001),\n",
        "                            loss=ComboModelTuner.custom_loss_mae,\n",
        "                            metrics=[ComboModelTuner.custom_loss_mse])\n",
        "\n",
        "        mae_per_fold_tr, mse_per_fold_tr = [], []\n",
        "        mae_per_fold_vd, mse_per_fold_vd = [], []\n",
        "\n",
        "        kfold = KFold(n_splits=splits_num, shuffle=True)\n",
        "        for j, (tr_idx, val_idx) in enumerate(kfold.split(model.features_train, model.data_train, model.labels_train)):\n",
        "            if data_generator:\n",
        "                history = model_keras.fit(learning_data_pool, epochs=total_hp[\"num_epochs_ll\"],\n",
        "                                          validation_data=([model.data_train[val_idx], model.features_train[val_idx]],\n",
        "                                                          model.labels_train[val_idx]))\n",
        "            else:\n",
        "                history = model_keras.fit(x=[model.data_train[tr_idx], model.features_train[tr_idx]],\n",
        "                                          y=model.labels_train[tr_idx],\n",
        "                                          batch_size=total_hp[\"batch_size_ll\"],\n",
        "                                          epochs=total_hp[\"num_epochs_ll\"],\n",
        "                                          validation_data=([model.data_train[val_idx], model.features_train[val_idx]],\n",
        "                                                          model.labels_train[val_idx]),\n",
        "                                          callbacks=callbacks)\n",
        "\n",
        "            scores = model_keras.evaluate(x=[model.data_train[tr_idx], model.features_train[tr_idx]],\n",
        "                                          y=model.labels_train[tr_idx])\n",
        "\n",
        "            mse_per_fold_tr.append(scores[0])\n",
        "            mae_per_fold_tr.append(scores[1])\n",
        "\n",
        "            scores = model_keras.evaluate(x=[model.data_train[val_idx], model.features_train[val_idx]],\n",
        "                                          y=model.labels_train[val_idx])\n",
        "\n",
        "            mse_per_fold_vd.append(scores[0])\n",
        "            mae_per_fold_vd.append(scores[1])\n",
        "            print(f\"Fold #{j + 1} finished succesfully\")\n",
        "\n",
        "        return [mae_per_fold_tr, mse_per_fold_tr, mae_per_fold_vd, mse_per_fold_vd]\n",
        "\n",
        "    @staticmethod\n",
        "    def random_hyper_tuning(iters_num: int, hps_cnn: dict,\n",
        "                            train_images_: np.ndarray, train_features_: np.ndarray, train_labels_: np.ndarray,\n",
        "                            test_images_: np.ndarray, test_features_: np.ndarray, test_labels_: np.ndarray):\n",
        "\n",
        "        valid_mae_label_1, valid_mae_label_2 = [], []\n",
        "        valid_mse_label_1, valid_mse_label_2 = [], []\n",
        "        valid_accuracy_label_1, valid_accuracy_label_2 = [], []\n",
        "\n",
        "        for iter_ in range(iters_num):\n",
        "            # Сборка комбинации случайных гиперпараметров в заданын границах\n",
        "            print(f\"Random Tuning iter #{iter_} started\")\n",
        "\n",
        "            cnn_hp_comb = {}\n",
        "\n",
        "            for param in hps_cnn:\n",
        "                if len(hps_cnn[param]) > 1:\n",
        "                    if any(isinstance(x, bool) for x in hps_cnn[param]) or \\\n",
        "                            any(isinstance(x, str) for x in hps_cnn[param]):\n",
        "                        cnn_hp_comb[param] = hps_cnn[param][np.random.randint(len(hps_cnn[param]))]\n",
        "                    else:\n",
        "                        cnn_hp_comb[param] = np.random.randint(low=min(hps_cnn[param]), high=max(hps_cnn[param]))\n",
        "                else:\n",
        "                    cnn_hp_comb[param] = hps_cnn[param][0]\n",
        "\n",
        "            print(cnn_hp_comb)\n",
        "\n",
        "            model = SimpleCNNModel(n_epochs=20,\n",
        "                                   n_row=200,\n",
        "                                   n_col=200,\n",
        "                                   input_channels=1,\n",
        "                                   random_seed=1234567890,\n",
        "                                   n_dict_features=30,\n",
        "                                   n_trait=2,\n",
        "                                   data_train=train_images_,\n",
        "                                   labels_train=train_labels_,\n",
        "                                   features_train=train_features_,\n",
        "                                   data_test=test_images_,\n",
        "                                   features_test=test_features_,\n",
        "                                   labels_test=test_labels_)\n",
        "\n",
        "            # model = SimpleCNNModel()\n",
        "            metrics = ComboModelTuner.fit_cv(total_hp={\"batch_size_ll\": 64, \"num_epochs_ll\": 20},\n",
        "                                             cnn_hp=cnn_hp_comb,\n",
        "                                             splits_num=5,\n",
        "                                             model=model,\n",
        "                                             early_stop=True)\n",
        "\n",
        "            # считаем ошибку модели на тестовой выборке\n",
        "            print(f\"Random Tuning iter #{iter_} finished successfully\")\n",
        "\n",
        "    @staticmethod\n",
        "    def grid_hyper_tuning(model: 'SimpleCNNModel', hps_cnn: dict, hps_reg: dict):\n",
        "        cnn_hp_combos = itertools.product(*hps_cnn)\n",
        "        reg_hp_combos = itertools.product(*hps_reg)\n",
        "\n",
        "        valid_mae_label_1, valid_mae_label_2 = [], []\n",
        "        valid_mse_label_1, valid_mse_label_2 = [], []\n",
        "        valid_accuracy_label_1, valid_accuracy_label_2 = [], []\n",
        "\n",
        "        for i, tmp_hps_cnn in enumerate(cnn_hp_combos):\n",
        "            for j, tmp_hps_reg in enumerate(reg_hp_combos):\n",
        "                model.fit(dict(tmp_hps_cnn), dict(tmp_hps_reg))\n",
        "\n",
        "                # считаем ошибку модели на тестовой выборке\n",
        "                valid_predict = model.predict\n",
        "                print(f\"Grid Tuning iter #{i * len(reg_hp_combos) + j} finished successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JU2Uemr52HkI"
      },
      "outputs": [],
      "source": [
        "# делим данные на обучение/валидацию/тест\n",
        "test_percentage = 0.1\n",
        "test_indices = np.random.choice(images.shape[0], int(images.shape[0] * test_percentage))\n",
        "train_indices = np.setdiff1d(np.array(list(range(images.shape[0]))), test_indices)\n",
        "\n",
        "train_images, train_labels, train_dict = images[train_indices], labels[train_indices], pca_features_[train_indices]\n",
        "test_images, test_labels, test_dict = images[test_indices], labels[test_indices], pca_features_[test_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FzfGemud2HsX",
        "outputId": "d901470a-060b-4757-9396-3dbfd9d7402e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tuning iter #0 started\n",
            "{'first_conv2d_out_channels': 53, 'first_conv2d_kernel_size': 3, 'first_conv2d_activation': 'tanh', 'need_extra_conv2d': False, 'extra_conv2d_out_channels': 35, 'extra_conv2d_kernel_size': 5, 'extra_conv2d_activation': 'tanh', 'need_batch_norm_after_first_conv2d': True, 'second_conv2d_kernel_size': 3, 'second_conv2d_out_channels': 107, 'second_conv2d_activation': 'relu', 'need_batch_norm_after_second_conv2d': True, 'dense_output_activation': 'linear', 'use_gap_1_or_flatten_0': 0, 'need_deconv_block': False, 'num_feature_output': 94}\n",
            "Epoch 1/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14s/step - custom_loss_mse: 171291.7812 - loss: 320.6811 \n",
            "Epoch 1: loss improved from inf to 369.57660, saving model to checkpoints/model_no_df_1.keras\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 16s/step - custom_loss_mse: 177290.2031 - loss: 324.7557 - val_custom_loss_mse: 144514.7500 - val_loss: 334.7500\n",
            "Epoch 2/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15s/step - custom_loss_mse: 243372.3438 - loss: 379.5270 \n",
            "Epoch 2: loss improved from 369.57660 to 361.66315, saving model to checkpoints/model_no_df_2.keras\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 16s/step - custom_loss_mse: 242384.4844 - loss: 378.0383 - val_custom_loss_mse: 391110.0000 - val_loss: 479.0929\n",
            "Epoch 3/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14s/step - custom_loss_mse: 281775.6875 - loss: 413.6284 \n",
            "Epoch 3: loss did not improve from 361.66315\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 15s/step - custom_loss_mse: 279892.2188 - loss: 412.2472 - val_custom_loss_mse: 163858.3906 - val_loss: 315.3264\n",
            "Epoch 4/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14s/step - custom_loss_mse: 200358.1562 - loss: 347.9746 \n",
            "Epoch 4: loss did not improve from 361.66315\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 15s/step - custom_loss_mse: 202367.2969 - loss: 349.1635 - val_custom_loss_mse: 51422.3125 - val_loss: 199.2231\n",
            "Epoch 4: early stopping\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - custom_loss_mse: 44301.7109 - loss: 180.1234\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - custom_loss_mse: 53511.6133 - loss: 202.6730\n",
            "Fold #1 finished succesfully\n",
            "Epoch 1/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14s/step - custom_loss_mse: 200775.3438 - loss: 339.2152 \n",
            "Epoch 1: loss did not improve from 361.66315\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 15s/step - custom_loss_mse: 204844.4688 - loss: 343.2915 - val_custom_loss_mse: 58899.8867 - val_loss: 200.7821\n",
            "Epoch 2/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - custom_loss_mse: 179240.5781 - loss: 313.3746 \n",
            "Epoch 2: loss improved from 361.66315 to 347.07074, saving model to checkpoints/model_no_df_2.keras\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 15s/step - custom_loss_mse: 181342.9531 - loss: 316.1826 - val_custom_loss_mse: 321599.5625 - val_loss: 445.7101\n",
            "Epoch 3/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14s/step - custom_loss_mse: 266631.1875 - loss: 402.1914 \n",
            "Epoch 3: loss did not improve from 347.07074\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 15s/step - custom_loss_mse: 265204.7812 - loss: 400.7525 - val_custom_loss_mse: 319285.6875 - val_loss: 447.0864\n",
            "Epoch 4/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14s/step - custom_loss_mse: 268118.8125 - loss: 415.3961 \n",
            "Epoch 4: loss did not improve from 347.07074\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 14s/step - custom_loss_mse: 267426.9375 - loss: 414.0174 - val_custom_loss_mse: 331699.7188 - val_loss: 439.2107\n",
            "Epoch 4: early stopping\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - custom_loss_mse: 334834.5625 - loss: 452.3872\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - custom_loss_mse: 341345.4062 - loss: 450.7155\n",
            "Fold #2 finished succesfully\n",
            "Epoch 1/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14s/step - custom_loss_mse: 236993.2656 - loss: 384.7013 \n",
            "Epoch 1: loss did not improve from 347.07074\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 15s/step - custom_loss_mse: 236950.1094 - loss: 384.7596 - val_custom_loss_mse: 237546.8281 - val_loss: 385.2267\n",
            "Epoch 2/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15s/step - custom_loss_mse: 254743.2500 - loss: 389.5547 \n",
            "Epoch 2: loss did not improve from 347.07074\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 16s/step - custom_loss_mse: 255887.9062 - loss: 390.4047 - val_custom_loss_mse: 182936.5625 - val_loss: 338.5728\n",
            "Epoch 2: early stopping\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - custom_loss_mse: 194849.1250 - loss: 363.5161\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - custom_loss_mse: 172702.9844 - loss: 334.3665\n",
            "Fold #3 finished succesfully\n",
            "Epoch 1/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14s/step - custom_loss_mse: 215469.0000 - loss: 372.1794 \n",
            "Epoch 1: loss did not improve from 347.07074\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 15s/step - custom_loss_mse: 216730.8438 - loss: 372.7737 - val_custom_loss_mse: 154273.0156 - val_loss: 315.5637\n",
            "Epoch 2/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14s/step - custom_loss_mse: 214536.7344 - loss: 360.9995 \n",
            "Epoch 2: loss did not improve from 347.07074\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 14s/step - custom_loss_mse: 218580.6250 - loss: 363.7479 - val_custom_loss_mse: 51050.4961 - val_loss: 183.2155\n",
            "Epoch 2: early stopping\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - custom_loss_mse: 61281.2969 - loss: 201.8741\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - custom_loss_mse: 50138.9258 - loss: 183.0657\n",
            "Fold #4 finished succesfully\n",
            "Epoch 1/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14s/step - custom_loss_mse: 214700.2188 - loss: 343.9675 \n",
            "Epoch 1: loss did not improve from 347.07074\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 15s/step - custom_loss_mse: 216776.0469 - loss: 345.8277 - val_custom_loss_mse: 58823.7930 - val_loss: 207.1110\n",
            "Epoch 2/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14s/step - custom_loss_mse: 222485.7500 - loss: 334.1368 \n",
            "Epoch 2: loss did not improve from 347.07074\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 15s/step - custom_loss_mse: 225394.5938 - loss: 336.3491 - val_custom_loss_mse: 66119.1016 - val_loss: 216.7005\n",
            "Epoch 2: early stopping\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - custom_loss_mse: 59866.1641 - loss: 207.5442\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - custom_loss_mse: 61366.3281 - loss: 210.3630\n",
            "Fold #5 finished succesfully\n",
            "Random Tuning iter #0 finished successfully\n",
            "Random Tuning iter #1 started\n",
            "{'first_conv2d_out_channels': 49, 'first_conv2d_kernel_size': 3, 'first_conv2d_activation': 'relu', 'need_extra_conv2d': False, 'extra_conv2d_out_channels': 62, 'extra_conv2d_kernel_size': 5, 'extra_conv2d_activation': 'tanh', 'need_batch_norm_after_first_conv2d': False, 'second_conv2d_kernel_size': 3, 'second_conv2d_out_channels': 65, 'second_conv2d_activation': 'tanh', 'need_batch_norm_after_second_conv2d': False, 'dense_output_activation': 'sigmoid', 'use_gap_1_or_flatten_0': 0, 'need_deconv_block': False, 'num_feature_output': 177}\n",
            "Epoch 1/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - custom_loss_mse: 148819.5781 - loss: 284.9063\n",
            "Epoch 1: loss improved from inf to 314.18277, saving model to checkpoints/model_no_df_1.keras\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7s/step - custom_loss_mse: 152131.8750 - loss: 287.3460 - val_custom_loss_mse: 464438.5000 - val_loss: 537.3531\n",
            "Epoch 2/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - custom_loss_mse: 267479.3750 - loss: 394.6369\n",
            "Epoch 2: loss did not improve from 314.18277\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 7s/step - custom_loss_mse: 265941.3438 - loss: 393.1038 - val_custom_loss_mse: 240653.2969 - val_loss: 388.1897\n",
            "Epoch 3/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - custom_loss_mse: 222143.5938 - loss: 349.9769\n",
            "Epoch 3: loss did not improve from 314.18277\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7s/step - custom_loss_mse: 223101.5938 - loss: 350.6695 - val_custom_loss_mse: 181729.0000 - val_loss: 345.5216\n",
            "Epoch 3: early stopping\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - custom_loss_mse: 143357.1406 - loss: 306.5486\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 702ms/step - custom_loss_mse: 185690.7031 - loss: 348.3198\n",
            "Fold #1 finished succesfully\n",
            "Epoch 1/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - custom_loss_mse: 255188.4375 - loss: 378.5200\n",
            "Epoch 1: loss did not improve from 314.18277\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7s/step - custom_loss_mse: 252749.4531 - loss: 376.2035 - val_custom_loss_mse: 272445.4062 - val_loss: 399.9639\n",
            "Epoch 2/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - custom_loss_mse: 210091.1094 - loss: 355.3178\n",
            "Epoch 2: loss did not improve from 314.18277\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 7s/step - custom_loss_mse: 212652.5000 - loss: 357.5317 - val_custom_loss_mse: 273459.0938 - val_loss: 427.4674\n",
            "Epoch 2: early stopping\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 890ms/step - custom_loss_mse: 256009.8125 - loss: 403.3508\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 831ms/step - custom_loss_mse: 261679.4375 - loss: 422.3332\n",
            "Fold #2 finished succesfully\n",
            "Epoch 1/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - custom_loss_mse: 283123.7188 - loss: 410.3947\n",
            "Epoch 1: loss did not improve from 314.18277\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 7s/step - custom_loss_mse: 280888.3438 - loss: 408.4887 - val_custom_loss_mse: 358626.5000 - val_loss: 400.6485\n",
            "Epoch 2/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - custom_loss_mse: 275452.7812 - loss: 384.8045\n",
            "Epoch 2: loss did not improve from 314.18277\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7s/step - custom_loss_mse: 272231.7500 - loss: 383.1034 - val_custom_loss_mse: 130574.0859 - val_loss: 283.0919\n",
            "Epoch 2: early stopping\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 872ms/step - custom_loss_mse: 162031.8906 - loss: 318.9440\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 692ms/step - custom_loss_mse: 126757.7812 - loss: 280.0911\n",
            "Fold #3 finished succesfully\n",
            "Epoch 1/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - custom_loss_mse: 194442.1875 - loss: 312.1469\n",
            "Epoch 1: loss did not improve from 314.18277\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 7s/step - custom_loss_mse: 199659.8594 - loss: 315.6559 - val_custom_loss_mse: 115389.9766 - val_loss: 268.1312\n",
            "Epoch 2/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - custom_loss_mse: 235616.0938 - loss: 371.1185\n",
            "Epoch 2: loss did not improve from 314.18277\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 7s/step - custom_loss_mse: 236079.4219 - loss: 371.7421 - val_custom_loss_mse: 265202.6562 - val_loss: 416.1845\n",
            "Epoch 2: early stopping\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - custom_loss_mse: 287257.4688 - loss: 424.6027\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - custom_loss_mse: 263007.0000 - loss: 422.2115\n",
            "Fold #4 finished succesfully\n",
            "Epoch 1/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - custom_loss_mse: 258729.7031 - loss: 397.1667\n",
            "Epoch 1: loss did not improve from 314.18277\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7s/step - custom_loss_mse: 258789.0625 - loss: 396.6273 - val_custom_loss_mse: 103644.1562 - val_loss: 270.4581\n",
            "Epoch 2/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - custom_loss_mse: 224460.6719 - loss: 371.6355\n",
            "Epoch 2: loss did not improve from 314.18277\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7s/step - custom_loss_mse: 225995.7656 - loss: 372.7166 - val_custom_loss_mse: 152263.1562 - val_loss: 295.0512\n",
            "Epoch 2: early stopping\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 922ms/step - custom_loss_mse: 150902.2500 - loss: 298.4804\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 694ms/step - custom_loss_mse: 135230.9844 - loss: 282.8210\n",
            "Fold #5 finished succesfully\n",
            "Random Tuning iter #1 finished successfully\n",
            "Random Tuning iter #2 started\n",
            "{'first_conv2d_out_channels': 50, 'first_conv2d_kernel_size': 4, 'first_conv2d_activation': 'tanh', 'need_extra_conv2d': False, 'extra_conv2d_out_channels': 40, 'extra_conv2d_kernel_size': 4, 'extra_conv2d_activation': 'relu', 'need_batch_norm_after_first_conv2d': False, 'second_conv2d_kernel_size': 4, 'second_conv2d_out_channels': 102, 'second_conv2d_activation': 'relu', 'need_batch_norm_after_second_conv2d': False, 'dense_output_activation': 'linear', 'use_gap_1_or_flatten_0': 0, 'need_deconv_block': False, 'num_feature_output': 113}\n",
            "Epoch 1/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - custom_loss_mse: 175064.0781 - loss: 325.3529 \n",
            "Epoch 1: loss improved from inf to 370.17157, saving model to checkpoints/model_no_df_1.keras\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 11s/step - custom_loss_mse: 180664.9844 - loss: 329.0878 - val_custom_loss_mse: 58722.8242 - val_loss: 212.0942\n",
            "Epoch 2/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - custom_loss_mse: 216252.3281 - loss: 345.1271 \n",
            "Epoch 2: loss did not improve from 370.17157\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 11s/step - custom_loss_mse: 219217.2656 - loss: 347.5114 - val_custom_loss_mse: 187663.9219 - val_loss: 330.6681\n",
            "Epoch 3/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - custom_loss_mse: 192771.6406 - loss: 343.8914 \n",
            "Epoch 3: loss did not improve from 370.17157\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 11s/step - custom_loss_mse: 196011.2500 - loss: 346.6284 - val_custom_loss_mse: 386843.1562 - val_loss: 509.6716\n",
            "Epoch 3: early stopping\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - custom_loss_mse: 386991.7812 - loss: 512.2214\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - custom_loss_mse: 366100.2188 - loss: 500.3414\n",
            "Fold #1 finished succesfully\n",
            "Epoch 1/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - custom_loss_mse: 305800.0625 - loss: 432.7806 \n",
            "Epoch 1: loss did not improve from 370.17157\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 11s/step - custom_loss_mse: 302827.3438 - loss: 430.1261 - val_custom_loss_mse: 45605.6758 - val_loss: 190.2037\n",
            "Epoch 2/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12s/step - custom_loss_mse: 238795.3906 - loss: 361.8121 \n",
            "Epoch 2: loss did not improve from 370.17157\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 13s/step - custom_loss_mse: 239604.9688 - loss: 363.3334 - val_custom_loss_mse: 147929.3750 - val_loss: 316.6683\n",
            "Epoch 2: early stopping\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - custom_loss_mse: 166338.0469 - loss: 324.4216\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - custom_loss_mse: 157055.1719 - loss: 329.3679\n",
            "Fold #2 finished succesfully\n",
            "Epoch 1/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - custom_loss_mse: 237845.7344 - loss: 375.8028 \n",
            "Epoch 1: loss did not improve from 370.17157\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 11s/step - custom_loss_mse: 239102.4375 - loss: 376.1255 - val_custom_loss_mse: 39146.0508 - val_loss: 177.5206\n",
            "Epoch 2/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - custom_loss_mse: 171712.8594 - loss: 312.4528 \n",
            "Epoch 2: loss improved from 370.17157 to 367.09634, saving model to checkpoints/model_no_df_2.keras\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 11s/step - custom_loss_mse: 176096.4375 - loss: 317.0064 - val_custom_loss_mse: 459608.0938 - val_loss: 533.1904\n",
            "Epoch 3/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - custom_loss_mse: 279329.4375 - loss: 392.7510 \n",
            "Epoch 3: loss did not improve from 367.09634\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 11s/step - custom_loss_mse: 278500.7188 - loss: 392.0751 - val_custom_loss_mse: 81672.3203 - val_loss: 238.7890\n",
            "Epoch 4/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - custom_loss_mse: 204507.2500 - loss: 337.5995 \n",
            "Epoch 4: loss improved from 367.09634 to 356.02881, saving model to checkpoints/model_no_df_4.keras\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 12s/step - custom_loss_mse: 205630.5781 - loss: 339.1353 - val_custom_loss_mse: 251605.9531 - val_loss: 406.3731\n",
            "Epoch 5/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - custom_loss_mse: 234311.1094 - loss: 380.8627 \n",
            "Epoch 5: loss did not improve from 356.02881\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 12s/step - custom_loss_mse: 234663.1875 - loss: 380.7740 - val_custom_loss_mse: 197070.9531 - val_loss: 376.8348\n",
            "Epoch 6/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - custom_loss_mse: 228214.5781 - loss: 375.1067 \n",
            "Epoch 6: loss did not improve from 356.02881\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 11s/step - custom_loss_mse: 228855.6094 - loss: 375.4580 - val_custom_loss_mse: 159249.0469 - val_loss: 302.0313\n",
            "Epoch 6: early stopping\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-f89af2011f45>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         }\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m ComboModelTuner.random_hyper_tuning(10, model_hp,\n\u001b[0m\u001b[1;32m     23\u001b[0m                                     \u001b[0mtrain_images_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                                     \u001b[0mtrain_labels_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-1dc5ddf82ac6>\u001b[0m in \u001b[0;36mrandom_hyper_tuning\u001b[0;34m(iters_num, hps_cnn, train_images_, train_features_, train_labels_, test_images_, test_features_, test_labels_)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;31m# model = SimpleCNNModel()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             metrics = ComboModelTuner.fit_cv(total_hp={\"batch_size_ll\": 64, \"num_epochs_ll\": 20},\n\u001b[0m\u001b[1;32m    182\u001b[0m                                              \u001b[0mcnn_hp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcnn_hp_comb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                                              \u001b[0msplits_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-1dc5ddf82ac6>\u001b[0m in \u001b[0;36mfit_cv\u001b[0;34m(total_hp, cnn_hp, model, splits_num, early_stop, model_checkpoint)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplits_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtr_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             history = model_keras.fit(x=[model.data_train[tr_idx], model.features_train[tr_idx]],\n\u001b[0m\u001b[1;32m    113\u001b[0m                                       \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtr_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                                       \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_hp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch_size_ll\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# задаем сетку гиперпараметров для\n",
        "\n",
        "model_hp = {# сначала идут параметры сверточной части модели\n",
        "            'first_conv2d_out_channels': [32, 64],\n",
        "            'first_conv2d_kernel_size': [3, 5, 7],\n",
        "            'first_conv2d_activation': ['tanh', 'relu'],\n",
        "            'need_extra_conv2d': [False, True],\n",
        "            'extra_conv2d_out_channels': [32, 64],\n",
        "            'extra_conv2d_kernel_size': [3, 5, 7],\n",
        "            'extra_conv2d_activation': ['tanh', 'relu'],\n",
        "            'need_batch_norm_after_first_conv2d': [True, False],\n",
        "            'second_conv2d_kernel_size': [3, 5],\n",
        "            'second_conv2d_out_channels': [64, 128],\n",
        "            'second_conv2d_activation': ['tanh', 'relu'],\n",
        "            'need_batch_norm_after_second_conv2d': [True, False],\n",
        "            'dense_output_activation': ['sigmoid', 'linear'],\n",
        "            'use_gap_1_or_flatten_0': [1, 0],\n",
        "            'need_deconv_block': [False, True],\n",
        "            'num_feature_output': [64, 128, 256],\n",
        "        }\n",
        "\n",
        "ComboModelTuner.random_hyper_tuning(10, model_hp,\n",
        "                                    train_images_=train_images,\n",
        "                                    train_labels_=train_labels,\n",
        "                                    train_features_=train_dict,\n",
        "                                    test_images_=test_images,\n",
        "                                    test_labels_=test_labels,\n",
        "                                    test_features_=test_dict)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}